{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install flashtext\n",
        "!pip install git+https://github.com/boudinfl/pke.git\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"brown\")\n",
        "!pip install transformers\n",
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQEGsgtNrqBx",
        "outputId": "a6f9c945-2f18-4684-b84d-e40691866c2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flashtext\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: flashtext\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9296 sha256=8bb79a63c3568d0ffdc5d9ce0fc39b8761dec6c49d743b83123bfe804e4e0034\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/be/39/c37ad168eb2ff644c9685f52554440372129450f0b8ed203dd\n",
            "Successfully built flashtext\n",
            "Installing collected packages: flashtext\n",
            "Successfully installed flashtext-2.7\n",
            "Collecting git+https://github.com/boudinfl/pke.git\n",
            "  Cloning https://github.com/boudinfl/pke.git to /tmp/pip-req-build-pazb4fe7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/boudinfl/pke.git /tmp/pip-req-build-pazb4fe7\n",
            "  Resolved https://github.com/boudinfl/pke.git to commit 69871ffdb720b83df23684fea53ec8776fd87e63\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (3.8.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (1.2.2)\n",
            "Collecting unidecode (from pke==2.0.0)\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (0.18.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (1.4.0)\n",
            "Requirement already satisfied: spacy>=3.2.3 in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->pke==2.0.0) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->pke==2.0.0) (2023.12.25)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pke==2.0.0) (3.4.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.2.3->pke==2.0.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.2.3->pke==2.0.0) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.2.3->pke==2.0.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.2.3->pke==2.0.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.2.3->pke==2.0.0) (0.1.4)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy>=3.2.3->pke==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=3.2.3->pke==2.0.0) (2.1.5)\n",
            "Building wheels for collected packages: pke\n",
            "  Building wheel for pke (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pke: filename=pke-2.0.0-py3-none-any.whl size=6160628 sha256=5d651ea8179ece19ddd88c26b7743d975585182f1bd4192278e2334b8d68c6ec\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nkum9k2h/wheels/8c/07/29/6b35bed2aa36e33d77ff3677eb716965ece4d2e56639ad0aab\n",
            "Successfully built pke\n",
            "Installing collected packages: unidecode, pke\n",
            "Successfully installed pke-2.0.0 unidecode-1.3.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "import spacy\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from flashtext import KeywordProcessor\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER, and word vectors\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def remove_subordinate_clauses(text):\n",
        "    # Process the text with spaCy\n",
        "    doc = nlp(text)\n",
        "    # Initialize an empty list to store the main clauses\n",
        "    main_clauses = []\n",
        "    # Iterate through each sentence\n",
        "    for sent in doc.sents:\n",
        "        # Check if the sentence contains a subordinate conjunction or a dependent clause\n",
        "        if any(token.dep_ == \"mark\" or token.dep_ == \"advcl\" for token in sent):\n",
        "            # Remove the subordinate clause\n",
        "            main_clause = \"\"\n",
        "            for token in sent:\n",
        "                if token.dep_ == \"mark\" or token.dep_ == \"advcl\":\n",
        "                    break\n",
        "                main_clause += token.text_with_ws\n",
        "            main_clauses.append(main_clause.strip())\n",
        "        else:\n",
        "            main_clauses.append(sent.text)\n",
        "    return main_clauses\n",
        "\n",
        "def tokenize_sentences(text):\n",
        "    \"\"\"\n",
        "    Tokenize the text into sentences.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text.\n",
        "\n",
        "    Returns:\n",
        "        list: List of tokenized sentences.\n",
        "    \"\"\"\n",
        "    sentences = remove_subordinate_clauses(text)\n",
        "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
        "    return sentences\n",
        "\n",
        "def get_named_entities(text):\n",
        "    \"\"\"\n",
        "    Extract named entities (proper nouns, location names, country names, organization names,\n",
        "    and specific common nouns) from the text using spaCy's Named Entity Recognition.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text.\n",
        "\n",
        "    Returns:\n",
        "        list: List of named entities.\n",
        "    \"\"\"\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(text)\n",
        "    entities = set()\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in ['ORG', 'LOC', 'GPE', 'PERSON']:\n",
        "            entities.add(ent.text)\n",
        "    return list(entities)\n",
        "\n",
        "def get_sentences_for_keyword(keywords, sentences):\n",
        "    \"\"\"\n",
        "    Get sentences containing the given keywords.\n",
        "\n",
        "    Args:\n",
        "        keywords (list): List of keywords.\n",
        "        sentences (list): List of sentences.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary mapping keywords to sentences.\n",
        "    \"\"\"\n",
        "    keyword_processor = KeywordProcessor()\n",
        "    keyword_sentences = {}\n",
        "    for word in keywords:\n",
        "        keyword_sentences[word] = []\n",
        "        keyword_processor.add_keyword(word)\n",
        "    for sentence in sentences:\n",
        "        keywords_found = keyword_processor.extract_keywords(sentence)\n",
        "        for key in keywords_found:\n",
        "            keyword_sentences[key].append(sentence)\n",
        "\n",
        "    for key in keyword_sentences.keys():\n",
        "        values = keyword_sentences[key]\n",
        "        values = sorted(values, key=len, reverse=True)\n",
        "        keyword_sentences[key] = values\n",
        "    return keyword_sentences\n",
        "\n",
        "def get_fill_in_the_blanks(sentence_mapping, max_questions=6):\n",
        "    \"\"\"\n",
        "    Generate fill-in-the-blanks questions from the given sentence mapping.\n",
        "\n",
        "    Args:\n",
        "        sentence_mapping (dict): Dictionary mapping keywords to sentences.\n",
        "        max_questions (int): Maximum number of questions to generate.\n",
        "\n",
        "    Returns:\n",
        "        dict: Fill-in-the-blanks questions with matching words at the top.\n",
        "    \"\"\"\n",
        "    out = {\"Q)\": \"Q) Fill in the blanks with matching words at the top : \"}\n",
        "    blank_sentences = []\n",
        "    keys = []\n",
        "    used_sentences = set()\n",
        "    question_count = 0\n",
        "    for key in sentence_mapping:\n",
        "        if len(sentence_mapping[key]) > 0:\n",
        "            for sent in sentence_mapping[key]:\n",
        "                if sent not in used_sentences and key.capitalize() not in keys:\n",
        "                    insensitive_sent = re.compile(re.escape(key), re.IGNORECASE)\n",
        "                    no_of_replacements = len(re.findall(re.escape(key), sent, re.IGNORECASE))\n",
        "                    line = insensitive_sent.sub(' _____________ ', sent)\n",
        "                    if no_of_replacements < 2:\n",
        "                        # Ensure the last symbol is a full stop\n",
        "                        if line[-1] not in string.ascii_letters:\n",
        "                            line = line.rstrip(string.punctuation) + \".\"\n",
        "                        blank_sentences.append(line)\n",
        "                        keys.append(key.capitalize())  # Capitalizing the options\n",
        "                        used_sentences.add(sent)\n",
        "                        question_count += 1\n",
        "                        if question_count >= max_questions:\n",
        "                            break\n",
        "        if question_count >= max_questions:\n",
        "            break\n",
        "    # Remove spaces around each item in Options and join them with commas\n",
        "    out[\"Options\"] = keys[:10]\n",
        "    # Remove the comma between questions\n",
        "    out[\"Questions\"] = blank_sentences[:10]\n",
        "\n",
        "    return out\n",
        "\n",
        "text = \"\"\"\n",
        "In the realm of Indian cinema, the 1990s marked an era of unparalleled achievements and cinematic marvels.\n",
        "From the iconic films that graced the silver screen to the unforgettable performances that captivated audiences worldwide, Bollywood witnessed a golden age of creativity and innovation.\n",
        "Under the visionary direction of luminaries like Yash Chopra and Subhash Ghai, Bollywood soared to new heights, producing timeless classics that continue to resonate with audiences to this day.\n",
        "Superstars such as Shah Rukh Khan, Madhuri Dixit, and Aamir Khan emerged as the reigning icons of Indian cinema, enchanting viewers with their charisma and versatility.\n",
        "Filming locations ranging from the picturesque valleys of Switzerland to the bustling streets of Mumbai provided the perfect backdrop for these cinematic masterpieces, transporting audiences to enchanting worlds of romance, drama, and intrigue.\n",
        "The 1990s also witnessed the rise of groundbreaking films like \"Dilwale Dulhania Le Jayenge\" and \"Hum Aapke Hain Koun..!\", which redefined the concept of blockbuster cinema and set new benchmarks for success in the industry.\n",
        "With its rich tapestry of stories, unforgettable music, and larger-than-life characters, the Bollywood of the 1990s remains an integral part of India's cultural heritage, continuing to inspire generations of filmmakers and audiences alike.\n",
        "\"\"\"\n",
        "\n",
        "sentences = tokenize_sentences(text)\n",
        "named_entities = get_named_entities(text)\n",
        "keyword_sentence_mapping = get_sentences_for_keyword(named_entities, sentences)\n",
        "fill_in_the_blanks = get_fill_in_the_blanks(keyword_sentence_mapping)\n",
        "\n",
        "# Printing the fill-in-the-blanks questions without JSON formatting\n",
        "print(fill_in_the_blanks[\"Q)\"])\n",
        "print(\"\\n\")\n",
        "print(fill_in_the_blanks[\"Options\"])\n",
        "print(\"\\n\")\n",
        "print(\"\\n\".join([f\"{i + 1}) {question}\" for i, question in enumerate(fill_in_the_blanks[\"Questions\"])]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceRwuX8gUJru",
        "outputId": "345983cf-4e8e-42d7-a844-294ad20d5123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q) Fill in the blanks with matching words at the top : \n",
            "\n",
            "\n",
            "['Hain koun', 'Subhash ghai', 'Switzerland', 'Aamir khan', 'India', 'Bollywood']\n",
            "\n",
            "\n",
            "1) The 1990s also witnessed the rise of groundbreaking films like \"Dilwale Dulhania Le Jayenge\" and \"Hum Aapke  _____________ .\n",
            "2) Under the visionary direction of luminaries like Yash Chopra and  _____________ , Bollywood soared to new heights.\n",
            "3) Filming locations ranging from the picturesque valleys of  _____________  to the bustling streets of Mumbai provided the perfect backdrop for these cinematic masterpieces.\n",
            "4) Superstars such as Shah Rukh Khan, Madhuri Dixit, and  _____________  emerged as the reigning icons of Indian cinema.\n",
            "5) With its rich tapestry of stories, unforgettable music, and larger-than-life characters, the Bollywood of the 1990s remains an integral part of  _____________ 's cultural heritage.\n",
            "6) From the iconic films that graced the silver screen to the unforgettable performances that captivated audiences worldwide,  _____________  witnessed a golden age of creativity and innovation.\n"
          ]
        }
      ]
    }
  ]
}